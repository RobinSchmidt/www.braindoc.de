<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
<head>
	<title>LPC-Vocoder Manual</title>
	<link rel=stylesheet type="text/css" href="../braindocsStyle.css">
</head>

<center><h1>LPC-Vocoder Manual</h1></center>

<TABLE align=center>
 <TR>
  <TD>
   <img src="screenshots/LPCVocoder368x412.jpg" width=368 height=412 alt=Screenshot>
  </TD>
 </TR>
</TABLE>

<p>
<strong>What is LPC-Vocoder?:</strong>
<br>
LPC-Vocoder is a VST-plugIn for the creation of vocoder-sounds. These are created by superimposing the frequency-envelope of one signal (the so called analysis- or modulatorsignal) on a second signal (the so called synthesis- or carriersignal). In the classic vocoder this is achieved by means of an analysis- and a synthesis-filterbank - the LPC-Vocoder in contrast uses a single adaptive filter which is capable of realizing complex frequency-responses with many peaks. LPC is an abbreviation of Linear Predictive Coding - a technique in signal processing which can extract the formants (frequency bands with high amplitude) out of an audio signal. LPC is widely used in the speech signal processing community, for example to compress the speech for transmission in digital communication systems. To analyze the input signal, a filter tries to predict the current value of the the signal by means of past signal values (this filter is called the "prediction-filter" or simply "predictor"). The error which occurs in this prediction can be used to adapt this predictor (the system which subtracts the predicted value from the actual, true value to form the error signal is called "prediction error filter").

<p>
<hr width="95%" size="2" noshade>
<p>
<strong>Analysis-Parameters:</strong>

<ul>
<li><strong>PreEmph:</strong>
Without going deeply into the technical details, it can be said, that in linear prediction it is assumed, that the signal has been generated by a source which has a white spectrum followed by a filter which formed the actual spectrum. Consequently this is called a source-filter signal model. If this model is not true - for example the spectrum of the source was not white - then the spectrum of the source can be compensated for with a proper pre-emphasis filter. We are talking about "white" signals when each frequency in the signal has the same amplitude - this is true for white noise and a comb of impulse functions. These are quite treble-dominated signals. With PreEmph you adjust the coefficient of a simple highpass filter, which should compensate for the spectrum of the source. If the coefficient is exactly 1, then this filter is a simple differentiator. In most cases, such a coefficient of one or close to one is the best choice.

<li><strong>Ord:</strong>
This is the order of the predictor filter. Higher orders are capable of realizing more complex frequency responses, but take more CPU-load.

<li><strong>Learn:</strong>
As we are dealing with an adaptive filter here, we want to be able to adjust the adaption- or learning rate. High learning rates lead to filters which can follow spectral changes in the input signal more quickly.

<li><strong>Forget:</strong>
If the filter would have infinite memory, then the whole history of the input signal would affect the filters frequency response at the current time instant. This is usually undesireable, because we don't want signal values which are long ago, to affect our filter at the "Now" moment. That's why a forgetting factor can be adjusted here.

<li><strong>Smooth:</strong>
This parameter somewhat smoothes out the learning process. 

<li><strong>Env-Att:</strong>
In addition to the analysis of the frequency content of the incoming signal, the overall amplitude envelope is analyzed via an envelope follower in order to apply this amplitude envelope to carrier signal, too. This is the attack time of the envelope follower.

<li><strong>Env-Rel:</strong>
The release time of the envelope follower.
</ul>

<p>
<hr width="95%" size="2" noshade>
<p>
<strong>Synthesis-Parameters:</strong>

<ul>
<li><strong>Whitening:</strong>
The small switch next to "Whitening" activates a filter, which filters the carrier-signal in such a way, that it has a white spectrum (as much as possible). The algorithm of this whitening filter is the same as the one used to analyze the modulator-signal. It  makes use of the fact that the prediction error signal is always a "whitened" version of the input signal. So the set of parameters for this filter is exactly the same as for the analysis filter (except the pre emphasis controller).

<li><strong>EnvAmt:</strong>
This control determines, how much the amplitude envelope of the modulator-signal should affect the amplitude of the carrier-signal. The unit is percent.

<li><strong>FiltAmt:</strong>
This control determines, how much the frequency envelope of the modulator-signal should affect the frequency envelope of the carrier-signal. The unit is also percent.
</ul>

<p>
<hr width="95%" size="2" noshade>
<p>
<strong>Mixer-Parameters:</strong>
<br>
In this analysis-/synthesis process there are several signals which can be routed via the mixer to the output of the plugIn:

<ul>
<li><strong>Voco:</strong>
This is the actual vocoder output signal, thus the carrier-signal with the frequency and amplitude envelope of the modulator-signal superimposed.

<li><strong>Err:</strong>
The prediction error signal of the analysis filter. This signal contains the non-predictable parts of the analysis signal, that is mostly transients and the source signal in the underlying source-filter model.

<li><strong>Mod:</strong>
The passed through modulator-signal.

<li><strong>Car:</strong>
The passed through carrier-signal.

<li><strong>whCar:</strong>
The "whitened" carrier-signal, i.e. the output signal of the whitening filter (only available if whitening is active).

<li><strong>Vol:</strong>
Controller for the overall volume.
</ul>

<p>
<hr width="95%" size="2" noshade>
<p>
<strong>Vocoders in practice:</strong>
<br>
As opposed to most other effects, the vocoder is an effect which needs two (independent) input signals. That's why you can't simply put a vocoder into an insert slot in the mixer of the chosen sequencer software. Instead, I recommend the following procedure: Create a group channel and route the two signals you want to use for vocoding to this group channel. LPC-Vocoder expects the carrier-signal on left and the modulator-signal on the right input channel - so adjust the pan-pot of the carrier to hard left and the pan-pot of the modulator to hard right. Plug in the vocoder in the group channel - this channel now contains the output signal of the vocoder. In particular to the LPC-Vocoder there is to say, that the adjustment of the parameters sometimes requires a little bit of sensibility because certain combinations of parameters lead to very loud output signals and in the worst case even to unstable synthesis filters. Especially the learning and forgetting rate are parameters which strongly interact. For this reason I recommend to start with checking out the presets first.

<p>
<hr width="95%" size="2" noshade>
<p>
Have much fun in making music, Braindoc.

</body>
</html>